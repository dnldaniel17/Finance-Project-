{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c4dcd365e7b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mbase_url_sec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"http://www.sec.gov\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mmaster_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Find all table row and then find all table data. Table data is like columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only count if cols is not equal to zero, AKA, the column headers row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import mplfinance as mpf\n",
    "import matplotlib.dates as mdates\n",
    "import pandas_datareader.data as web\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "style.use('ggplot')\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "\n",
    "#The goal of this project is to automate the scraping, organizing, cleaning, and storing of the balance sheet,\n",
    "#income statement, and cash flow statement for all publicly traded companies that have filed there 10-k, 20-F, or 40-F\n",
    "\n",
    "ticker = 'aig'.upper() \n",
    "end = datetime.now()\n",
    "ticker_list = pd.read_excel(\"/Users/danieldaniel/Companies_list.xlsx\")\n",
    "ticker_list_final = ticker_list.iloc[0:5407,0:3].to_numpy()\n",
    "if ticker in ticker_list_final:\n",
    "    \n",
    "    ticker_url = r\"https://www.sec.gov/files/company_tickers.json\"\n",
    "    content = requests.get(ticker_url)\n",
    "    decoded_ticker_content = content.json() # JSON structure that will turn into a python dictionary.\n",
    "    \n",
    "    ticker_content_df = pd.DataFrame(decoded_ticker_content)\n",
    "    ticker_content_df_clean = ticker_content_df.T\n",
    "\n",
    "    ID = ticker_content_df_clean[ticker_content_df_clean['ticker']==ticker.upper()].index.values\n",
    "    ID_num = int(ID)\n",
    "\n",
    "    cik_num = ticker_content_df_clean.iloc[ID_num, 0]\n",
    "    cik_num_str = str(cik_num)\n",
    "\n",
    "    ticker_content_df_clean.iloc[ID_num,:]\n",
    "\n",
    "    \n",
    "# PASSING DICT PARAMETERS\n",
    "    find_no_id = []\n",
    "    Financial_statement_type = ['10-K','20-F','40-F']\n",
    "    for file_type in Financial_statement_type:\n",
    "        endpoint = r\"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "\n",
    "        param_dict = {'action': 'getcompany',\n",
    "                      'CIK' : cik_num_str,\n",
    "                      'type' : file_type, # 40-F Annual reports - Canadian issuers \n",
    "                      'dateb' : end,  # Change date to now, use datetime.now() so it refreshes everyday.\n",
    "                      'owner' : 'exclude',\n",
    "                      'start': '',\n",
    "                      'output': '',\n",
    "                      'count' : '20'}\n",
    "\n",
    "        response = requests.get(url = endpoint, params = param_dict)\n",
    "        soup  = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    #     print('Request Successful') # Let the user know that it was successful\n",
    "    #     print(response.url)\n",
    "\n",
    "    \n",
    "# SCRAPE AND SAVE FINANCIALS DATA\n",
    "        doc_table = soup.find_all('table', class_= 'tableFile2') # Pull the whole table: (table class=\"tableFile2\")\n",
    "        base_url_sec = r\"http://www.sec.gov\"\n",
    "        master_list = []\n",
    "        for row in doc_table[0].find_all('tr'):   # Find all table row and then find all table data. Table data is like columns\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) != 0:  # Only count if cols is not equal to zero, AKA, the column headers row\n",
    "\n",
    "                filing_type = cols[0].text.strip() # Which file term - 10-K or 10-K/A, 20-F or 20-F/A, 40-F or 40-F/A, etc.\n",
    "                filing_date = cols[3].text.strip() # When was the file posted, by date.\n",
    "\n",
    "                filing_doc_href = cols[1].find('a', {'href': True, 'id':'documentsbutton'})    # Pull all documents href\n",
    "                filing_id_href = cols[1].find('a', {'href': True, 'id':'interactiveDataBtn'}) # Pull all interactive data href\n",
    "\n",
    "                if filing_doc_href != None:     # if filing_doc_href equals something. It is a double negative\n",
    "                    filing_doc_link = base_url_sec + filing_doc_href['href']\n",
    "                else:\n",
    "                    filing_doc_link = 'no link'\n",
    "\n",
    "                if filing_id_href != None:\n",
    "                    filing_id_link = base_url_sec + filing_id_href['href']\n",
    "                else:\n",
    "                    filing_id_link = 'no link'\n",
    "\n",
    "                file_dict = {}\n",
    "                file_dict['file_type'] = filing_type\n",
    "                file_dict['file_date'] = filing_date\n",
    "                file_dict['links'] = {}\n",
    "                file_dict['links']['documents'] = filing_doc_link\n",
    "                file_dict['links']['interactive_data'] = filing_id_link\n",
    "\n",
    "    #             print('-'*100)\n",
    "    #             print('Filing Type: ' + filing_type)\n",
    "    #             print('Filing Date: ' + filing_date)\n",
    "    #             print('Document Link: ' + filing_doc_link)\n",
    "    #             print('Interactive Data Link: ' + filing_id_link)\n",
    "\n",
    "                master_list.append(file_dict)\n",
    "                find_no_id.append(filing_id_link)\n",
    "\n",
    "\n",
    "    all_xml_forms = []\n",
    "    Financial_statement_type = ['10-K','20-F','40-F']\n",
    "    for file_type in Financial_statement_type:\n",
    "        endpoint = r\"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "\n",
    "        param_dict = {'action': 'getcompany',\n",
    "                      'CIK' : cik_num_str,\n",
    "                      'type' : file_type, # 40-F Annual reports - Canadian issuers \n",
    "                      'dateb' : end,  # Change date to now, use datetime.now() so it refreshes everyday.\n",
    "                      'owner' : 'exclude',\n",
    "                      'start': '',\n",
    "                      'output': 'atom',\n",
    "                      'count' : '100'}\n",
    "        ##\n",
    "        response = requests.get(url = endpoint, params = param_dict)\n",
    "        soup  = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "    #     print('Request Successful') # Let the user know that it was successful\n",
    "    #     print(response.url)\n",
    "\n",
    "        entries = soup.find_all('entry')\n",
    "\n",
    "        master_list_xml = []\n",
    "\n",
    "        for entry in entries[0:10]:  #Only include years with 'act' variable in xml structure: entries[0:17]\n",
    "\n",
    "            accession_num = entry.find('accession-number').text\n",
    "\n",
    "            entry_dict = {}\n",
    "            entry_dict[accession_num] = {}\n",
    "\n",
    "            category_info = entry.find('category')\n",
    "            entry_dict[accession_num]['category'] = {}\n",
    "            entry_dict[accession_num]['category']['label'] = category_info['label']\n",
    "            entry_dict[accession_num]['category']['scheme'] = category_info['scheme']\n",
    "            entry_dict[accession_num]['category']['term'] = category_info['term'] # Which file term - 10-K or 10-K/A, 20-F or 20-F/A, 40-F or 40-F/A, etc.\n",
    "\n",
    "            entry_dict[accession_num]['file_info'] = {}\n",
    "        #     entry_dict[accession_num]['file_info']['act'] = entry.find('act').text \n",
    "            # There is no 'act' variable in the xml structure until 2005 for all companies, so an error will follow by running \n",
    "            # this cell. Must not include act variable to get files for all of the years.\n",
    "            entry_dict[accession_num]['file_info']['file_number'] = entry.find('file-number').text\n",
    "            entry_dict[accession_num]['file_info']['file_number_href'] = entry.find('file-number-href').text\n",
    "            entry_dict[accession_num]['file_info']['filing_date'] = entry.find('filing-date').text\n",
    "            entry_dict[accession_num]['file_info']['filing_href'] = entry.find('filing-href').text\n",
    "            entry_dict[accession_num]['file_info']['filing_type'] = entry.find('filing-type').text\n",
    "            entry_dict[accession_num]['file_info']['form_number'] = entry.find('film-number').text\n",
    "            entry_dict[accession_num]['file_info']['form_name'] = entry.find('form-name').text\n",
    "            entry_dict[accession_num]['file_info']['file_size'] = entry.find('size').text\n",
    "\n",
    "            entry_dict[accession_num]['request_info'] = {}\n",
    "            entry_dict[accession_num]['request_info']['link'] = entry.find('link')['href']\n",
    "            entry_dict[accession_num]['request_info']['title'] = entry.find('title').text\n",
    "            entry_dict[accession_num]['request_info']['last_updated'] = entry.find('updated').text  \n",
    "\n",
    "            master_list_xml.append(entry_dict)\n",
    "\n",
    "    #         print('-'*100)\n",
    "    #         print(entry.find('category')['term'])\n",
    "    #         print(entry.find('updated').text[0:-1]) # only print up until the date, not the time of the day.\n",
    "    #     ##    print(entry.find('form-name').text)\n",
    "    #     ##    print(entry.find('file-number').text)\n",
    "    #     ##    print(entry.find('file-number-href').text)\n",
    "    #         print(entry.find('link')['href'])\n",
    "            all_xml_forms.append(entry.find('link')['href'])\n",
    "\n",
    "    find_no_id\n",
    "    indices_html = [index for index, element in enumerate(find_no_id) if element == 'no link'] # The count starts at zero.\n",
    "    # print('List of indices with no links: ', indices_html)\n",
    "\n",
    "    look = [x.split('-')[1] for x in all_xml_forms]\n",
    "    # print('Years in each link: ',look)\n",
    "\n",
    "    def Repeat(x): \n",
    "        size = len(x) \n",
    "        repeated = [] \n",
    "        for i in range(size): \n",
    "            k = i + 1\n",
    "            for j in range(k, size): \n",
    "                if x[i] == x[j] and x[i] not in repeated: \n",
    "                    repeated.append(x[i]) \n",
    "        return repeated \n",
    "\n",
    "    repeat = Repeat(look)\n",
    "    # print('Which year or years are repeated: ',repeat)\n",
    "\n",
    "    repeat_1 = ''.join(map(str,repeat))\n",
    "    n = 2\n",
    "    repeat_list = [repeat_1[i:i+n] for i in range(0, len(repeat_1), n)]\n",
    "\n",
    "    indices_xml = [[i for i in range(len(look)) if look[i] == r] for r in repeat_list]\n",
    "    indices_xml_new = [x for sublist in indices_xml for x in sublist]\n",
    "    # print('List of indices of years repeated: ',indices_xml_new)\n",
    "\n",
    "    combined_indices = sorted(indices_xml_new + indices_html)\n",
    "    # print('List of indices combined: ',combined_indices)\n",
    "\n",
    "    drop_indices = Repeat(combined_indices)\n",
    "    # print('Which indices to drop in our combined list: ',drop_indices)\n",
    "\n",
    "    iterable = iter(indices_xml_new)\n",
    "    drop = []\n",
    "    for x in iterable:\n",
    "        drop_it = min(x, next(iterable))\n",
    "        drop.append(drop_it)\n",
    "    # print(drop)\n",
    "    final_links = [i for j, i in enumerate(all_xml_forms) if j not in drop]\n",
    "    \n",
    "    # All of this code above only drops the urls that have no interactive data links with repeated years as well, but\n",
    "    # I must decide how to show companies that have no interactive data for all of the years.\n",
    "    pic_a_year = final_links[0:1]\n",
    "\n",
    "    listToStr = ' '.join(map(str, pic_a_year))\n",
    "\n",
    "    listToStr_clean = \"/\".join(listToStr.split(\"/\")[:-1])\n",
    "\n",
    "    files_url = listToStr_clean + \"/index.json\"\n",
    "\n",
    "    base_url = r\"http://www.sec.gov\"\n",
    "\n",
    "    documents_url = files_url\n",
    "\n",
    "    content = requests.get(documents_url).json()\n",
    "\n",
    "    for file in content['directory']['item']:\n",
    "\n",
    "        if file['name'] == 'FilingSummary.xml':\n",
    "\n",
    "            xml_summary = base_url + content['directory']['name'] + '/' + file['name']\n",
    "\n",
    "    #         print('-'*100)\n",
    "    #         print('File Name: ' + file['name'])\n",
    "    #         print('File Path: ' + xml_summary)\n",
    "\n",
    "    base_url = xml_summary.replace('FilingSummary.xml','')\n",
    "    # Replace FilingSummary.xml with a blank space-Output: http://www.sec.gov/Archives/edgar/data/1318605/000156459019003165/\n",
    "    content = requests.get(xml_summary).content\n",
    "\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "    reports = soup.find('myreports')\n",
    "\n",
    "    short_list = []\n",
    "\n",
    "    master_reports = []\n",
    "\n",
    "    for report in reports.find_all('report')[0:20]: # find all reports in 'myreports' except for the last 'myreport'\n",
    "\n",
    "        report_dict = {}\n",
    "        report_dict['name_short'] = report.shortname.text\n",
    "        report_dict['name_long'] = report.longname.text\n",
    "        report_dict['position'] = report.position.text\n",
    "        report_dict['category'] = report.menucategory.text\n",
    "        report_dict['url'] = base_url + report.htmlfilename.text\n",
    "\n",
    "        master_reports.append(report_dict)\n",
    "        short_list.append(report_dict['name_short'])\n",
    "    #     print('-'*100)\n",
    "    #     print(base_url + report.htmlfilename.text)\n",
    "    #     print(report.longname.text)\n",
    "    #     print(report.shortname.text)\n",
    "    #     print(report.menucategory.text)\n",
    "    #     print(report.position.text)\n",
    "\n",
    "\n",
    "    item1 = ''\n",
    "    item2 = ''\n",
    "    item3 = ''\n",
    "    item4 = ''\n",
    "    state = []\n",
    "    statement_url = []\n",
    "    for report_dict in master_reports:\n",
    "        for short in short_list[0:20]:\n",
    "            if short in ['Consolidated Statements of Income and of Comprehensive Income','Combined Statements of Profit or Loss and Other Comprehensive Income','Consolidated Statements of Net Earnings (Loss)','CONSOLIDATED STATEMENTS OF LOSS (PROFIT) AND OTHER COMPREHENSIVE LOSS (PROFIT)','CONSOLIDATED STATEMENTS OF EARNINGS AND COMPREHENSIVE EARNINGS','Consolidated Statement of Loss and Comprehensive Income (Loss)','CONSOLIDATED STATMENTS OF OPERATIONS','Consolidated Statements of Earnings and Comprehensive Income (Loss)','Consolidated Statements of Net Earnings and Comprehensive (Loss) Income','Consolidated statements of loss and comprehensive loss','Amended and Restated Consolidated Statements of Loss and Comprehensive Loss','Consolidated Statements of Earnings (Loss) Statement','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE EARNINGS (LOSS)','Consolidated Statments of Earnings','Consolidated statements of earnings','Consolidated statements of income and other comprehensive income','Consolidated statements of income and comprehensive income','COMBINED AND CONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME (LOSS)','CONSOLIDATED STATEMENT OF OPERATIONS AND COMPREHENSIVE INCOME (LOSS)','Statements of income','Consolidated Statements Of Profit Or Loss And Other Comprehensive Income','CONSOLIDATED STATEMENT OF PROFIT OR LOSS AND OTHER COMPREHENSIVE INCOME','CONSOLIDATED STATEMENTS OF COMPREHENSIVE (LOSS) /INCOME','Consolidated statements of income (loss) and comprehensive income (loss)','Consolidated Statements of Operations and Comprehensive Loss (Successor Basis)','CONSOLIDATED AND COMBINED STATEMENTS OF PROFIT OR LOSS AND OTHER COMPREHENSIVE INCOME','Consolidated Statements of Income/(Loss) and Comprehensive Income/(Loss)','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE (LOSS)/INCOME','CONSOLIDATED STATEMENTS OF (LOSS)/INCOME','Consolidated Statements of Operations and Comprehensive Income (loss)','CONSOLIDATED STATEMENTS OF PROFIT AND LOSS AND OTHER COMPREHENSIVE INCOME','COMBINED AND CONSOLIDATED STATEMENTS OF OPERATIONS','Statements of Income/(Loss)','Consolidated statement of operations','Consolidated Statement of Income (Loss)','Consolidated Statements of Loss and Other Comprehensive Loss','Consolidated Statement of Profit or Loss and Comprehensive Income','Consolidated Statements of Profit & Loss','Statements of Loss and Comprehensive Loss','Consolidated Statement of Operations and Comprehensive Loss','Consolidated Statement of Profit or Loss and Other Comprehensive Income / (Loss)','Consolidated statements of profit or loss and total comprehensive income or loss','CONSOLIDATED STATEMENTS OF PROFIT OR LOSS AND OTHER COMPREHENSIVE INCOME OR LOSS','Consolidated Statements of Income/(Loss)','CONSOLIDATED STATEMENTS OF OPERATIONS','Consolidated statement of profit or loss and other comprehensive loss','CONSOLIDATED STATEMENTS OF PROFIT AND OTHER COMPREHENSIVE INCOME','Consolidated Statement of Profit or Loss and Other Comprehensive Income (Loss)','Statements of Earnings and Comprehensive Loss (Twelve Month and Month Ended 2017 Unaudited)','CONSOLIDATED STATEMENTS OF PROFIT AND LOSS','Consolidated Statements of Profit and Loss','Consolidated Statemenets of Operations','Consolidated statements of net income (loss)','CONSOLIDATED STATEMENTS OF OPERATING RESULTS','Consolidated statement of profit or loss and other comprehensive income','Consolidated Statements of Comprehensive (Loss) /  Income','Consolidated Statements of Operations and Comprehensive Loss (Income)','Group Income Statement','Consolidated Statement of Profit (Loss) and Other Comprehensive Income','CONSOLIDATED STATEMENTS OF INCOME AND COMPREHENSIVE INCOME/(LOSS)','Consolidated Statements of Profit or Loss and Other Comprehensive Loss','Consolidated Statements of Loss and Comprehensive Loss (Income)','Statements of Profit or Loss','Consolidated income statements','Consolidated statements of profit or loss and other comprehensive income','Statement of profit or loss','CONSOLIDATED STATEMENT OF INCOME BY FUNCTION','Consolidated Statements of Profit or Loss','Consolidated Statements of Profit and Loss and Other Comprehensive Income','Consolidated statement of profit or loss','Consolidated Statement of Profit or Loss and Other Comprehensive Income','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE (LOSS) / INCOME','Group Income Statements','CONSOLIDATED PROFIT AND LOSS ACCOUNT','CONSOLIDATED STATEMENTS OF PROFIT OR LOSS AND OTHER COMPREHENSIVE INCOME','Consolidated Statements of Profit or Loss and Other Comprehensive Income (Loss)','Consolidated Statement of Profit or Loss','CONSOLIDATED STATEMENT OF PROFIT OR LOSS','Consolidated statements of profit or loss','GROUP INCOME STATEMENT','Financial Statements - Consolidated Income Statements','CONSOLIDATED STATEMENTS OF PROFIT OR LOSS','Consolidated income statement of Aegon N.V.','Consolidated Statements of Profit or Loss and Other Comprehensive Income','Income statements','Consolidated income statement','Income Statement','Group income statement','Consolidated Statements of Income and Other Comprehensive Income','Consolidated Statements of Earnings (Losses)','Combined Statements of Operations and Comprehensive Loss','Statement of Operations and Comprehensive Income','Statements of Operations and Comprehensive (Loss) Income','CONSOLIDATED STATEMENTS OF INCOME (Unaudited)','Combined and Consolidated Statements of Operations','Consolidated and Combined Consolidated Statements of Operations','Consolidated and Combined Statements of Income','Consolidated Statements of (Loss)','CONDENSED CONSOLIDATED STATEMENTS OF (LOSS) EARNINGS','Condensed Statements of Operations and Comprehensive Loss','COMBINED AND CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME (LOSS)','Statements of Operations and Comprehensive Income','Consolidated & Combined Statements of Operations','Statement of Operations','CONSOLIDATED COMBINED STATEMENTS OF OPERATIONS','Condensed Consolidated and Combined Statements of Income','Condensed Interim Statements of Operations','Consolidated and Combined Statements of Operations and Comprehensive Income','Consolidated and Combined Statements of Operations and Comprehensive Loss','Statements of Operation and Comprehensive Loss','CONSOLIDATED AND COMBINED STATEMENT OF OPERATIONS','CONSOLIDATED AND COMBINED STATEMENTS OF OPERATIONS','Consolidated and Combined Statements of Income (Loss)','Consolidated and Combined Statements of Operations','Consolidated and Combined Statements of Operations and Comprehensive (Loss) Income','Consolidated and Combined Statements of (Loss) Income','Consolidated Statements of Earnings and Comprehensive Earnings (Loss)','Consolidated Statements of Operations and Comprehensive Loss (Unaudited)','Consolidated statements of income','Condensed Consolidated Statements of Operations and Comprehensive Loss (Unaudited)','CONSOLIDATED STATEMENTS OF LOSS AND COMPREHENSIVE LOSS','Consolidated Statements of Operations and Comprehensive Earnings','COMBINED CONSOLIDATED STATEMENTS OF OPERATIONS','CONDENSED STATEMENTS OF OPERATIONS','Combined Statements of Operations','Consolidated statements of operations and comprehensive income','STATEMENTS OF INCOME','Consolidated Statements of Operations Statement','CONSOLIDATED STATEMENT OF INCOME (LOSS) AND COMPREHENSIVE INCOME (LOSS)','Consolidated Statements of (Loss) Income and Comprehensive (Loss) Income','CONSOLIDATED STATEMENTS OF NET AND COMPREHENSIVE INCOME','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME (HD Supply, Inc.)','Statement of Consolidated Operations and Comprehensive Loss','STATEMENT OF OPERATIONS AND COMPREHENSIVE LOSS','CONDENSED CONSOLIDATED STATEMENT OF OPERATIONS (unaudited)','CONSOLIDATED STATEMENTS OF INCOME AND COMPREHENSIVE INCOME (LOSS)','Condensed Consolidated Statements of Operations and Comprehensive Income','Condensed Statements of Operations','Consolidated Statements of Net Loss','Condensed Consolidated Statements of Operations and Comprehensive Income (Loss)','Statements of operations','Condensed Consolidated Statement of Operations','CONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME','Condensed Consolidated Statements of Loss and Comprehensive Loss','Consolidated statements of operations and comprehensive loss','FIRST FINANCIAL NORTHWEST, INC. AND SUBSIDIARIES CONSOLIDATED INCOME STATEMENTS','Condensed Consolidated Statements of Operations and Comprehensive Loss','Statements Of Income','Consolidated Statements Of Income (Loss)','Consolidated Statements of Earnings (Loss) and Comprehensive Income (Loss)','Consolidated Statements of Income and Expenses (Unaudited)','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE OPERATIONS (Unaudited)','CONSOLIDATED STATEMENTS OF INCOME/(LOSS)','Consolidated Statements of Operations and Other Comprehensive Loss','Consolidated statements of operations','Statements of Income and Expenses','CONSOLIDATED STATEMENTS OF OPERATIONS Statement','Consolidated Statements of Earnings and Other Comprehensive Income','Unaudited Condensed Statements of Operations','CONSOLIDATED STATEMENTS OF LOSS','Statement Of Operations','Consolidated Statements of Operations and Other Comprehensive (Loss) Income','Consolidated Income Statements (Unaudited)','CONSOLIDATED STATEMENTS OF EARNINGS (LOSS) AND COMPREHENSIVE ( LOSS) INCOME','CONSOLIDATED STATEMENTS OF INCOME AND COMPREHENSIVE LOSS','Consolidated Statements of Income or Loss','Consolidated Condensed Statements of Income (Operations) (Unaudited)','CONSOLIDATED CONDENSED STATEMENTS OF INCOME','CONSOLIDATED STATEMENTS OF OPERATIONS (LOSS)','Audited Consolidated Statements of Operations and Comprehensive Income (Loss)','Statements Of Consolidated Income (Loss)','Consolidated Statements of Loss','Consolidated Statements of Earnings and Comprehensive (Loss) Income','Consolidated Statements Of Income (Loss) And Comprehensive Income (Loss)','Consolidated Statements of (Loss)/Income and Comprehensive (Loss)/Income','Consolidated Statements of Operation and Comprehensive Loss','Statements of Operations And Comprehensive Loss','Consolidated Statement of income','Consolidated Statements of Operations And Comprehensive Loss','Consolidated Statements of Income Statement','Consolidated Statement of Operations and Comprehensive Income (Loss)','Consolidated Statements Of Income and Comprehensive Income','Statements of Operations and Comprehensive Loss','Consolidated Statements of Income and Other Comprehensive Income (Loss)','CONSOLIDATED STATEMENTS OF EARNINGS AND COMPREHENSIVE INCOME','CONDENSED CONSOLIDATED STATEMENT OF INCOME','Consolidated Statements of (Loss) / Income','CONSOLIDATED STATEMENTS OF OPERATIONS CONSOLIDATED STATEMENTS OF OPERATIONS','Consolidated Statements of (Loss) Income and Comprehensive Income','Unaudited Condensed Consolidated Statements of Operations','CONSOLIDATED STATEMENTS OF OPERATIONS AND STATEMENTS OF OTHER COMPREHENSIVE INCOME/(LOSS)','CONSOLIDATED STATEMENTS OF EARNINGS, COMPREHENSIVE INCOME AND RETAINED EARNINGS','CONDENSED CONSOLIDATED STATEMENTS OF EARNINGS AND COMPREHENSIVE INCOME','Consolidated Statements Of (Loss) Earnings','BorgWarner Inc. and Consolidated Subsidiaries Consolidated Statements of Operations','STATEMENTS OF OPERATIONS AND COMPREHENSIVE LOSS','Consolidated Statements Of Operations and Comprehensive Income','Condensed Consolidated Statements of Operations (Unaudited)','CONSOLIDATED STATEMENTS OF INCOME AND OTHER COMPREHENSIVE INCOME','CONSOLIDATED STATEMENT OF OPERATIONS AND COMPREHENSIVE INCOME','UNAUDITED CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE LOSS','JEWETT-CAMERON TRADING COMPANY LTD. AND SUBSIDIARIES CONSOLIDATED STATEMENTS OF OPERATIONS','CONSOLIDATED STATEMENTS OF (LOSS) EARNINGS','CONSOLIDATED STATEMENTS OF (LOSS) INCOME AND COMPREHENSIVE (LOSS) INCOME','CONSOLIDATED STATEMENTS OF INCOME (LOSS) AND COMPREHENSIVE INCOME (LOSS)','Consolidated Statements of Loss and Comprehensive Loss','Consolidated Statements of Operations and Comprehensive Income/(Loss)','STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME (LOSS)','STATEMENT OF OPERATIONS','Consolidated Statements of Operations and Other Comprehensive Income (Loss)','CONDENSED STATEMENTS OF OPERATIONS AND COMPREHENSIVE LOSS','CONSOLIDATED STATEMENTS OF OPERATIONS (Unaudited)','Consolidated Statements of Net Income','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME OR LOSS','CONSOLIDATED STATEMENTS OF OPERATIONS Consolidated Statement of Operations','Consolidated Statements of (Loss) Income','Carnival Corporation & PLC Consolidated Statements of Income','Consolidated Statements Of Operations And Comprehensive Loss','CONSOLIDATED STATEMENTS OF OPERATIONS AND OTHER COMPREHENSIVE INCOME (LOSS)','CONSOLIDATED AND COMBINED STATEMENTS OF INCOME','Consolidated Statements of Income (Loss) and Comprehensive Income (Loss)','CONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE LOSS','Consolidated Statements of Net Income and Comprehensive Income','Consolidated Statements of Operations and Comprehensive Income / (Loss)','Consolidated Statements Of Operations And Comprehensive Income','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE (LOSS) INCOME','Consolidated Statements of Income and Total Comprehensive Income','Consolidated Statements of Operations and Comprehensive Earnings and Loss','Consolidated Statements of Operations and Comprehensive Income','Condensed Consolidated Statements of Earnings and Comprehensive Earnings','Consolidated Statements of Operations and Comprehensive (Loss) Income','Consolidated Statements of Income and Comprehensive Income (Loss)','Consolidated Statements Of Income And Other Comprehensive Income','Condensed Consolidated Income Statements Of Income and Comprehensive Income','Consolidated Statements Of Income And Comprehensive Income','CONSOLIDATED STATEMENT OF INCOME AND COMPREHENSIVE INCOME','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME (LOSS)','CONSOLIDATED STATEMENTS OF INCOME AND COMPREHENSIVE INCOME','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME (LOSS) (Audited)','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE LOSS','Consolidated Statements of Operations and Comprehensive Income (Loss)','Consolidated Statements of Earnings and Comprehensive Earnings','Consolidated Statements Of Operations And Comprehensive Income (Loss)','Consolidated Statements of Earnings and Comprehensive Income','Consolidated Statements of Operations and Comprehensive Loss','Consolidated Statements of Income and Comprehensive Income','CONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME (LOSS)','Statements of Earnings','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE (LOSS)','STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME','Consolidated Statements Of Operations And Comprehensive (Loss) Income','CONSOLIDATED STATEMENTS OF INCOME/(LOSS) AND COMPREHENSIVE INCOME/(LOSS)','CONSOLIDATED STATEMENTS OF OPERATIONS & COMPREHENSIVE INCOME','Consolidated Statements of Net Loss and Comprehensive Loss','Statements Of Condensed Consolidated Operations','Consolidated Statements of Operation','CONDENSED CONSOLIDATED STATEMENTS OF INCOME','CONSOLIDATED STATEMENTS OF OPERATIONS AND COMPREHENSIVE INCOME (LOSS)','CONSOLIDATED STATEMENTS OF NET (LOSS) INCOME','UTAH MEDICAL PRODUCTS, INC. CONSOLIDATED STATEMENT OF INCOME','CONSOLIDATED STATEMENTS OF OPERATIONS (in thousands, except per share data)','Condensed Consolidated Statements of Income','STATEMENT OF CONSOLIDATED INCOME','Statements Of Operations','CONSOLIDATED STATEMENT OF OPERATIONS','CONSOLIDATED STATEMENTS OF NET INCOME','Statements of Consolidated Operations','Consolidated Statements of Operations Consolidated Statements of Operations','CONSOLIDATED STATEMENTS OF EARNINGS AND RETAINED EARNINGS','CONSOLIDATED RESULTS OF OPERATIONS','Consolidated Statements of Net Earnings','CONSOLIDATED STATEMENT OF INCOME (LOSS)','CONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS','Consolidated Statements Of Net Income','Consolidated Statements Of Income And Earnings Reinvested In The Business','Statements of Consolidated Income','Statements of Income','Consolidated Statement of Income Statement','CONSOLIDATED STATEMENTS OF INCOME AND RETAINED EARNINGS','Consolidated Income Statement','CONSOLIDATED STATEMENTS OF OPERATIONS (Audited)','Consolidated Statements of Operations (Unaudited)','Statement of Income','STATEMENTS OF CONSOLIDATED INCOME','Consolidated Statement of Income Consolidated Statement of Income','STATEMENT OF EARNINGS (LOSS)','CONSOLIDATED INCOME STATEMENT','Consolidated Statement of Income','Consolidated Statement Of Income','STATEMENTS OF CONSOLIDATED OPERATIONS','STATEMENTS OF OPERATIONS','STATEMENTS OF EARNINGS','CONSOLIDATED STATEMENT OF INCOME','INCOME STATEMENTS','Consolidated statement of income','Consolidated Statement of Operations','CONSOLIDATED STATEMENTS OF (LOSS) INCOME','Consolidated Statement Of Operations','CONSOLIDATED STATEMENT OF EARNINGS','Consolidated Statement Of Income (Loss)','Consolidated Statements of Income (Loss)','Consolidated Statements of Earnings (Loss)','CONSOLIDATED STATEMENTS OF EARNINGS','Condensed Statements of Income','Statements Of Consolidated Earnings','Consolidated Statements Of Income','Consolidated Statements Of Earnings','CONSOLIDATED INCOME STATEMENTS','Consolidated Results of Operations','STATEMENT OF CONSOLIDATED OPERATIONS','Consolidated Statements of Earnings','Statement of Consolidated Income','Statement of Consolidated Operations','Consolidated Statements Of Operations','CONSOLIDATED STATEMENTS OF INCOME (LOSS)','Consolidated Statements of Income','Consolidated Income Statements','Condensed Consolidated Statements of Operations','Statements of Operations','CONSOLIDATED STATEMENTS OF OPERATIONS','Consolidated Statements of Operations','CONSOLIDATED STATEMENTS OF INCOME','Consolidated Statement of Earnings','Condensed Consolidated Statements of Income (Unaudited)']:\n",
    "                item1 = (r\"{}\").format(short)\n",
    "            if short in ['CONDENSED CONSOLIDATED STATEMENTS OF COMPREHENSIVE LOSS','Statements of comprehensive income (loss)','Consolidated Statements of Comprehensive Income/(Loss) (Details)','Statement of Net and Comprehensive Loss','Consolidated Statements of Comprehensive (Loss)/Income','COMBINED AND CONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME','CONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME (Details)','Consolidated Statements Of Comprehensive Loss','Consolidated Statement of Comprehensive Income/(Loss)','Consolidated Statements of Comprehensive Income /(Loss)','Consolidated statement of comprehensive loss','COMBINED STATEMENTS OF COMPREHENSIVE INCOME','Consolidated Statement of Comprehensive Loss','Statements of Comprehensive Loss','CONSOLIDATED STATEMENTS OF COMPREHENSIVE (LOSS)/INCOME','Consolidated Statements of Comprehensive Income/ (Loss)','CONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME/ (LOSS)','CONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME/(LOSS)','Statement of Comprehensive Income/(Loss)','Consolidated statement of comprehensive income','CONSOLIDATED STATEMENT OF COMPREHENSIVE INCOME (LOSS)','CONSOLIDATED COMPREHENSIVE INCOME STATEMENT','Consolidated Statements of Comprehensive Income, by Nature','Consolidated statements of comprehensive income','Statements of Consolidated Comprehensive Income','Statements of Consolidated Comprehensive Income (Loss)','Consolidated Of  Statements of Comprehensive Income','CONSOLIDATED STATEMENT OF COMPREHENSIVE LOSS','CONSOLIDATED STATEMENTS OF COMPREHENSIVE (LOSS) INCOME','Consolidated statements of comprehensive loss','Condensed Consolidated Statements of Comprehensive Income (Unaudited)','CONSOLIDATED STATEMENT OF COMPREHENSIVE INCOME','Condensed Statements of Comprehensive Loss','Statements of Comprehensive Income (Loss)','STATEMENTS OF COMPREHENSIVE LOSS','Consolidated Statements of Comprehensive Earnings','UNAUDITED CONDENSED CONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME (LOSS)','Condensed Consolidated Statements of Comprehensive Income','Consolidated Statements of Comprehensive Income (Unaudited)','Consolidated Statements of Comprehensive Loss','Consolidated Statements of Total Comprehensive Income','Consolidated Statement of Comprehensive Income (Loss)','Consolidated Statements of Comprehensive Income (Loss) (Unaudited)','Consolidated Statement Of Comprehensive Income (Loss)','CONSOLIDATED STATEMENTS OF COMPREHENSIVE LOSS','Statements Of Comprehensive Income (Loss)','Consolidated Statement of Comprehensive Income','Consolidated Statements Of Comprehensive Income (Loss)','Consolidated Comprehensive Income Statements','CONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME (LOSS)','Consolidated Statements Of Comprehensive Income','Consolidated Statements of Comprehensive (Loss) Income','CONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME','Consolidated Statements of Comprehensive Income (Loss)','Statements of Comprehensive Income','Consolidated Statements of Comprehensive Income','Consolidated Statements of Comprehensive (Loss)']:\n",
    "                item2 = (r\"{}\").format(short) #all statement that have income and comprehensive. Add to item1. First one is an example.\n",
    "            if short in ['Combined Statements of Financial Position','CONDENSED STATEMENTS OF FINANCIAL POSITION','Amended and Restated Consolidated Statements of Financial Position','Consolidated Statements of Balance Sheets','Consolidated Statements of Financial Position Statement','Statements of financial position','COMBINED AND CONSOLIDATED BALANCE SHEETS','Consolidated Balance Sheets (Successor Basis)','STATEMENTS OF CONSOLIDATED BALANCE SHEETS','COMBINED STATEMENTS OF FINANCIAL POSITION','Statements of Consolidated Financial Position','Consolidated Statetments of Financial Position','Consolidated Statement Of Financial Position','Group Balance Sheet','Statements of Financial Position','Group Balance Sheets','Consolidated statements of financial position','CONSOLIDATED STATEMENT OF FINANCIAL POSITION','Group statement of financial position','GROUP BALANCE SHEET','Financial Statements - Balance sheets','Consolidated statement of financial position','Consolidated statement of financial position of Aegon N.V.','Statement of financial position','Group balance sheet','Combined Balance Sheets','CONDENSED BALANCE SHEET','Combined and Consolidated Balance Sheets','Consolidated and Combined Consolidated Balance Sheets','Condensed Balance Sheet','Condensed Consolidated and Combined Balance Sheets','CONSOLIDATED AND COMBINED BALANCE SHEETS','Consolidated and Combined Balance Sheets','COMBINED CONSOLIDATED BALANCE SHEETS','Combined Statements of Financial Condition','Combined Statements of Assets and Liabilities','CONSOLIDATED STATEMENT OF FINANCIAL CONDITION','CONSOLIDATED BALANCE SHEETS (HD Supply Holdings, Inc.)','Condensed Statements of Financial Condition','STATEMENTS OF ASSETS AND LIABILITIES','Balance sheets','Condensed Consolidated Balance Sheet','FIRST FINANCIAL NORTHWEST, INC. AND SUBSIDIARIES CONSOLIDATED BALANCE SHEETS','Consolidated balance sheets','Statement of Financial Condition','CONSOLIDATED BALANCE SHEETS Statement','Statements of Assets and Liabilities','Balance Sheet','Statement - Consolidated Condensed Balance Sheets (Unaudited)','CONSOLIDATED CONDENSED BALANCE SHEETS','Consolidated Balance Sheets, as of December 31','CONDENSED CONSOLIDATED BALANCE SHEET','Consolidated Condensed Statements of Financial Condition','Unaudited Condensed Consolidated Balance Sheets','STATEMENTS OF FINANCIAL POSITION','BorgWarner Inc. and Consolidated Subsidiaries Consolidated Balance Sheets','Consolidated Balance Sheets Consolidated Balance Sheets','Condensed Consolidated Balance Sheets (Unaudited)','Consolidated Balance Sheets Statement','Consolidated Balance Sheets (Unaudited)','JEWETT-CAMERON TRADING COMPANY LTD. AND SUBSIDIARIES CONSOLIDATED BALANCE SHEETS','BALANCE SHEET','CONDENSED BALANCE SHEETS','Statements of Financial Condition','Carnival Corporation & PLC Consolidated Balance Sheets','Consolidated Balance Sheets (Current Period Unaudited)','Statements Of Condensed Consolidated Financial Position','Consolidated Statement of Financial Condition','Consolidated Statements Of Condition','UTAH MEDICAL PRODUCTS, INC. CONSOLIDATED BALANCE SHEET','Audited Consolidated Balance Sheets','CONSOLIDATED BALANCE SHEETS (in thousands, except share data)','Consolidated Statements Of Financial Condition','Consolidated Statement of Condition','CONDENSED CONSOLIDATED BALANCE SHEETS','CONSOLIDATED STATEMENTS OF FINANICAL POSITION','Consolidated Balance Sheet Statement','Condensed Consolidated Balance Sheet & Mini Balance Sheet','Statement of Financial Position','Consolidated Statements of Condition','Consolidated Balance Sheet & Mini Balance Sheet','STATEMENT OF FINANCIAL POSITION','CONSOLIDATED BALANCE SHEETS (Audited)','CONSOLIDATED STATEMENTS OF CONDITION','CONSOLIDATED STATEMENTS OF FINANCIAL CONDITION','BALANCE SHEETS','Consolidated balance sheet','Consolidated Statement of Financial Position','Consolidated Statements of Financial Position','Consolidated Statements of Financial Condition','Consolidated Financial Position','CONSOLIDATED STATEMENTS OF FINANCIAL POSITION','Condensed Balance Sheets','Consolidated Statements Of Financial Position','CONSOLIDATED BALANCE SHEET','Condensed Consolidated Balance Sheets','Balance Sheets','CONSOLIDATED BALANCE SHEETS','Consolidated Balance Sheets','Consolidated Balance Sheet']:\n",
    "                item3 = (r\"{}\").format(short)\n",
    "            if short in ['Consolidated Statements of Cash Flows (Details)','Consolidated Statements of Cashflows','Amended and Restated Consolidated Statements of Cash Flows','Condensed consolidated statement of cash flows','Statements of cash flows','Consolidated Statements of Cash Flows (Successor Basis)','CONSOLIDATED STATEMENTS OF CASHFLOWS','COMBINED STATEMENTS OF CASH FLOWS','Consolidated Statement of Cash Flows Consolidated Statement of Cash Flows','Cash Flows','Statements of Cash Flows (Twelve Month and Month Ended 2017 Unaudited)','Consolidated Statemenets of Cash Flows','Statements of Cash Flow','Consolidated Statements Of Cash Flows','Group Cash Flow Statement','CONSOLIDATED CASH FLOW STATEMENT','Statements of Cash Flows-Indirect Method','Consolidated cash flow statements','CONSOLIDATED STATEMENT OF CASH FLOWS DIRECT - METHOD','Group Cash Flow Statements','CONSOLIDATED CASH FLOWS STATEMENT','Consolidated Statements of Cash Flows, Direct','Consolidated statements of cash flow','CONSOLIDATED STATEMENT OF CASH FLOW','Consolidated statement of cash flow','Group Statements of cash flows','GROUP CASH FLOW STATEMENT','Financial Statements - Statements of cash flows','Consolidated cash flow statement of Aegon N.V.','Cash flow statements','Statement of Cash Flows in the Consolidated Group','Statement of cash flows','Group cash flow statement','Consolidated cash flow statement','CONDENSED STATEMENT OF CASH FLOWS','Combined and Consolidated Statements of Cash Flows','Consolidated and Combined Consolidated Statements of Cash Flows','Condensed Statement of Cash Flows','CONSOLIDATED AND COMBINED STATEMENT OF CASH FLOW','Consolidated and Combined Statement of Cash Flows','COMBINED AND CONSOLIDATED STATEMENTS OF CASH FLOWS','Consolidated & Combined Statements of Cash Flows','CONSOLIDATED COMBINED STATEMENTS OF CASH FLOWS','Condensed Consolidated and Combined Statements of Cash Flows','Condensed Interim Statement of Cash Flows','Consolidated and Combined Statements of Cash Flows (Unaudited)','CONSOLIDATED AND COMBINED STATEMENT OF CASH FLOWS','Consolidated Statements of Cash flows','CONSOLIDATED STATEMENTS OFCASH FLOWS','STATEMENTS OF CASH FLOW','Consolidated Statements of Cash Flows (unaudited)','Combined Statements of Cash Flows','Consolidated and Combined Statements of Cash Flows','Condensed Consolidated Statements of Changes in Cash Flows','Condensed Consolidated Statements of Cash Flow (Unaudited)','CONSOLIDATED STATEMENTS OF CHANGES OF CASH FLOWS','CONSOLIDATED STATEMENTS OF CASH FLOWS (HD Supply Holdings, Inc.)','CONDENSED CONSOLIDATED STATEMENTS OF CASH FLOWS (Unaudited)','CONSOLIDATED STATEMENTS OF CASH FLOWS, (Unaudited)','Statements of Cash Flows Statement','CONSOLIDATED CASH FLOWS STATEMENTS','Statements of cash flows','FIRST FINANCIAL NORTHWEST, INC. AND SUBSIDIARIES CONSOLIDATED STATEMENTS OF CASH FLOWS','Statements of Cash Flows (Unaudited)','Consolidated statements of cash flows','CONSOLIDATED STATEMENTS OF CASH FLOWS Statement','Consolidated statements of Cash Flows','Statement Of Cash Flows','CONSOLIDATED CONDENSED STATEMENTS OF CASH FLOWS','Consolidated Statements of Cash Flow Statement','Consolidated Statments of Cash Flows','Audited Consolidated Statements of Cash Flows','Consolidated Statements Of Changes Of Cash Flows','CONDENSED CONSOLIDATED STATEMENT OF CASH FLOWS','UNAUDITED CONDENSED CONSOLIDATED STATEMENTS OF CASH FLOWS','Consolidated Cash Flows Statements','BorgWarner Inc. and Consolidated Subsidiaries Consolidated Statements of Cash Flows','CONSOLIDATED STATEMENTS OF CASH FLOWS (in thousands)','UNAUDITED CONSOLIDATED STATEMENTS OF CASH FLOWS','Consolidated Statements Of Cash Flow','JEWETT-CAMERON TRADING COMPANY LTD. AND SUBSIDIARIES CONSOLIDATED STATEMENTS OF CASH FLOWS','CONDENSED STATEMENTS OF CASH FLOWS','Consolidated Statement of Cash Flows Statement','Consolidated Statements of Cash Flows Statement','CONSOLIDATED STATEMENTS OF CASH FLOWS (Unaudited)','Carnival Corporation & PLC Consolidated Statements of Cash Flows','Consolidated Statement of Cash Flows (Statement)','CONSOLIDATED AND COMBINED STATEMENTS OF CASH FLOWS','Statements Of Condensed Consolidated Cash Flows','CONSOLIDATED STATEMENT OF CASH FLOWS (Unaudited)','CONSOLIDATED STATEMENTS OF CASH FLOWS (unaudited)','UTAH MEDICAL PRODUCTS, INC. CONSOLIDATED CONDENSED STATEMENT OF CASH FLOW','Consolidated Cash Flow Statements','CONSOLIDATED STATEMENT OF CASH FLOWS (in thousands)','CONSOLIDATED CASH FLOW STATEMENTS','CONSOLIDATED CASH FLOWS','CONDENSED CONSOLIDATED STATEMENTS OF CASH FLOWS','Consolidated Statements Of Capitalization','Statements of Consolidated Cash Flows','Consolidated Cash Flow Statement','Condensed Consolidated Statement of Cash Flows','CONSOLIDATED STATEMENTS OF CASHFLOWS (Audited)','Consolidated Statements of Cash Flows (Unaudited)','Statement of Cash Flows','CONSOLIDATED STATEMENTS of CASH FLOWS','Condensed Consolidated Statements of Cash Flows (Unaudited)','STATEMENT OF CASH FLOWS','CONSOLIDATED STATEMENTS OF CASH FLOWS (Audited)','Consolidated Statements of Cash Flow','CONSOLIDATED STATEMENTS OF CASH FLOW','STATEMENTS OF CONSOLIDATED CASH FLOWS','Statements Of Cash Flows','STATEMENTS OF CASH FLOWS','CASH FLOWS STATEMENTS','Consolidated statement of cash flows','Consolidated Statement Of Cash Flows','Consolidated Statement of Cash Flow','CONSOLIDATED STATEMENT OF CASH FLOWS','Condensed Statements of Cash Flows','Statements Of Consolidated Cash Flows','STATEMENT OF CONSOLIDATED CASH FLOWS','Statement of Consolidated Cash Flows','Consolidated Statements Of Cash Flows','Condensed Consolidated Statements of Cash Flows','Statements of Cash Flows','CONSOLIDATED STATEMENTS OF CASH FLOWS','Consolidated Statements of Cash Flows','Consolidated Statement of Cash Flows']:\n",
    "                item4 = (r\"{}\").format(short)\n",
    "        if item4 == 'Statements of cash flows' and 'Consolidated Statements Of Cash Flows':\n",
    "            item4 = 'Consolidated Statements Of Cash Flows'\n",
    "        if item3 == 'Statements of financial position' and item1 == 'Statements of income': # This conditional pulls the CF statement for LINX.\n",
    "            item4 = 'Statements of cash flows'\n",
    "\n",
    "        report_list = [item3, item4, item1, item2]\n",
    "        if item1 and item2 in report_list:\n",
    "            del report_list[3]\n",
    "    #     elif item2 in report_list:\n",
    "    #         report_list = [item3, item4, item2]\n",
    "        else: \n",
    "            item2 in report_list\n",
    "            report_list = [item3, item4, item2]\n",
    "        if report_dict['name_short'] in report_list:\n",
    "\n",
    "    #         print('-'*100)\n",
    "    #         print(report_dict['name_short'])\n",
    "    #         print(report_dict['url'])\n",
    "\n",
    "            statement_url.append(report_dict['url'])\n",
    "            state.append(report_dict['name_short'])\n",
    "\n",
    "\n",
    "    state_ = [x.replace(item3,'Balance Sheet').replace(item4,'Cash Flow').replace(item1 or item2,'Income Statement') for x in state]\n",
    "    list1 = statement_url\n",
    "    list2 = state_\n",
    "\n",
    "    zipped_lists = zip(list2, list1)\n",
    "\n",
    "    sorted_zipped_lists = sorted(zipped_lists)\n",
    "    sorted_list1 = [element for _, element in sorted_zipped_lists]\n",
    "\n",
    "    statements_data = []\n",
    "\n",
    "    for statement in sorted_list1:\n",
    "\n",
    "        statement_data = {}\n",
    "        statement_data['headers'] = []\n",
    "        statement_data['sections'] = []\n",
    "        statement_data['data'] = []\n",
    "\n",
    "        content = requests.get(statement).content\n",
    "        report_soup = BeautifulSoup(content, 'html')\n",
    "\n",
    "        for index, row in enumerate(report_soup.table.find_all('tr')):\n",
    "\n",
    "            columns = row.find_all('td')\n",
    "\n",
    "            if(len(row.find_all('th')) == 0 and len(row.find_all('strong')) == 0):\n",
    "\n",
    "                regular_row = [element.text.strip() for element in columns]\n",
    "                statement_data['data'].append(regular_row)\n",
    "\n",
    "            elif(len(row.find_all('th')) == 0 and len(row.find_all('strong')) != 0):\n",
    "\n",
    "                section_row = columns[0].text.strip()\n",
    "                statement_data['sections'].append(section_row)\n",
    "\n",
    "            elif(len(row.find_all('th')) != 0):\n",
    "\n",
    "                header_row = [element.text.strip() for element in row.find_all('th')]\n",
    "                statement_data['headers'].append(header_row)\n",
    "\n",
    "            else:\n",
    "                 print('There is an error!')\n",
    "\n",
    "        statements_data.append(statement_data)\n",
    "else:\n",
    "    print('This company is not supported on our platform or is not in our publicly traded list.')\n",
    "    \n",
    "\n",
    "# ORGANIZING AND CLEANING BALANCE SHEET - AUTOMATED \n",
    "financial_statement = []\n",
    "def Number_of_lists(anything): \n",
    "    return len(anything)\n",
    "count_2_bs = ''\n",
    "count_1_bs = ''\n",
    "count = Number_of_lists(statements_data[0]['headers'])\n",
    "if count == 2:\n",
    "    x = statements_data[0]['headers']\n",
    "    count_2_bs = sum(x, [])\n",
    "    if count_2_bs[1] == '12 Months Ended':\n",
    "        del[count_2_bs[1]]\n",
    "#     print('count 2: ', count_2_bs)\n",
    "else:\n",
    "    if count == 1:\n",
    "        count_1_bs = statements_data[0]['headers'][0]\n",
    "#     print('count 1: ', count_1_bs)\n",
    "balance_sheet_headers = count_2_bs or count_1_bs\n",
    "# print('Before:',balance_sheet_headers)\n",
    "drop_1_headers_bs = []\n",
    "string_bs = ['[1]','[2]','[3]','[4]','[1],[2]']\n",
    "for i in range(0, len(balance_sheet_headers)) : \n",
    "    if balance_sheet_headers[i] in string_bs : \n",
    "        drop_1_headers_bs.append(i) \n",
    "new_headers_bs = [j for i, j in enumerate(balance_sheet_headers) if i not in drop_1_headers_bs]\n",
    "# print('After:',new_headers_bs)\n",
    "balance_sheet_headers = [n.replace('\\n','| ') for n in new_headers_bs]\n",
    "\n",
    "balance_sheet_data = statements_data[0]['data']\n",
    "example_bs = balance_sheet_data[0:]\n",
    "balance_sheet_data_ = examples_bs = [[x.replace('[1]','').replace('[2]', '').replace('[3]', '').replace('[4]', '') for x in i] for i in example_bs]\n",
    "# balance_sheet_data_ = examples_bs\n",
    "balance_sheet_df = pd.DataFrame(balance_sheet_data_)\n",
    "\n",
    "balance_sheet_df.index = balance_sheet_df[0] # Make index like column zero \n",
    "# balance_sheet_df.index.name = balance_sheet_headers[0].replace(' ', '')\n",
    "balance_sheet_df.index.name = balance_sheet_headers[0].split('-')[1].replace(' ', '').replace('(', '').replace(')', '').replace(',', '').replace('$', '')\n",
    "balance_sheet_df = balance_sheet_df.drop(0, axis = 1)\n",
    "\n",
    "balance_sheet_df = balance_sheet_df.replace('[/$,R,,,,,CAD,,,,SFr,)]', '', regex = True)\\\n",
    "                     .replace('[(]','-', regex = True)\\\n",
    "                     .replace('', np.nan, regex = True)\\\n",
    "                     .replace('[/None)]', np.nan, regex = True)\n",
    "\n",
    "array_balance_sheet = np.array(balance_sheet_headers[1:]).size   # Count the number of elements for list\n",
    "# print(array_balance_sheet)\n",
    "sum_NaNs_balance_sheet = (balance_sheet_df.isnull().sum())   # Find sum of all null values for each column\n",
    "# print(sum_NaNs_balance_sheet)\n",
    "# print(sum_NaNs_balance_sheet.size)\n",
    "if sum_NaNs_balance_sheet.size == array_balance_sheet:\n",
    "    balance_sheet_df = balance_sheet_df.astype(float)\n",
    "    balance_sheet_df.columns = balance_sheet_headers[1:]\n",
    "    balance_sheet_df.columns = balance_sheet_df.columns.str.replace(',', '_').str.replace('.', '_').str.replace(' ', '') #######\n",
    "balance_sheet_df\n",
    "\n",
    "if sum_NaNs_balance_sheet.size != array_balance_sheet: #and sum_NaNs_balance_sheet.size > array_balance_sheet:       # If the number of elements do not match, subtract the difference.\n",
    "    how_many_nums_to_delete_balance_sheet = sum_NaNs_balance_sheet.size - (sum_NaNs_balance_sheet.size - array_balance_sheet)\n",
    "#     print(how_many_nums_to_delete_balance_sheet)\n",
    "    p_l_balance_sheet = list(sum_NaNs_balance_sheet)                 # Convert sum of all null values into a list and sort lowest value to\n",
    "    p_l_balance_sheet.sort(reverse=False)                 # to highest value.\n",
    "    # print(p_l_balance_sheet[0:how_many_nums_to_delete_balance_sheet])  # Then, slice it to the number equal to array_income.\n",
    "\n",
    "    max_new_list_balance_sheet = max(p_l_balance_sheet[0:how_many_nums_to_delete_balance_sheet]) # Find max of sliced list\n",
    "    bs_df = balance_sheet_df.loc[:, (balance_sheet_df.isnull().sum(axis=0) <= max_new_list_balance_sheet)] #Delete columns with a certain amount of null values.\n",
    "\n",
    "    bs_df = bs_df.rename(index={'': 'Empty'})\n",
    "    bool_value = bs_df.index == 'Empty'\n",
    "    index_number = np.where(bool_value)[0]\n",
    "    int_value = int(index_number[0:1])\n",
    "\n",
    "    bs_df[0:int_value]\n",
    "    balance_sheet_df = bs_df[0:int_value].astype(float)\n",
    "    balance_sheet_df.columns = balance_sheet_headers[1:]\n",
    "    balance_sheet_df.columns = balance_sheet_df.columns.str.replace(',', '_').str.replace('.', '_').str.replace(' ', '') #######\n",
    "balance_sheet_df\n",
    "    \n",
    "    \n",
    "    \n",
    "# ORGANIZING AND CLEANING CASH FLOW STATEMENT - AUTOMATED \n",
    "cf_headers = statements_data[1]['headers'][1]\n",
    "# print('Before:',cf_headers)\n",
    "drop_1_headers_cf = []\n",
    "string_cf = ['[1]','[2]','[3]','[4]','[1],[2]']\n",
    "for i in range(0, len(cf_headers)) : \n",
    "    if cf_headers[i] in string_cf : \n",
    "        drop_1_headers_cf.append(i) \n",
    "new_headers_cf = [j for i, j in enumerate(cf_headers) if i not in drop_1_headers_cf]\n",
    "# print('After:',new_headers_cf)\n",
    "cf_headers = [n.replace('\\n','| ') for n in new_headers_cf]\n",
    "\n",
    "cf_main_header = statements_data[1]['headers'][0]\n",
    "\n",
    "cf_data = statements_data[1]['data']\n",
    "example_cf = cf_data[0:]\n",
    "cf_data_ = examples_cf = [[x.replace('[1]','').replace('[2]', '').replace('[3]', '').replace('[4]', '') for x in i] for i in example_cf]\n",
    "# cf_data_ = examples_cf\n",
    "cf_df = pd.DataFrame(cf_data_)\n",
    "\n",
    "cf_df.index = cf_df[0] # Make index like column zero \n",
    "# cf_df.index.name = cf_main_header[0]\n",
    "cf_df.index.name = cf_main_header[0].split('-')[1].replace(' ', '').replace('(', '').replace(')', '').replace(',', '').replace('$', '')\n",
    "cf_df = cf_df.drop(0, axis = 1)\n",
    "\n",
    "cf_df = cf_df.replace('[/$,R,,,,,CAD,,,,SFr,)]', '', regex = True)\\\n",
    "                     .replace('[(]','-', regex = True)\\\n",
    "                     .replace('', np.nan, regex = True)\\\n",
    "                     .replace('[/None)]', np.nan, regex = True)\n",
    "\n",
    "array_cf = np.array(cf_headers).size   # Count the number of elements for list\n",
    "# print(array_cf)\n",
    "sum_NaNs_cf = (cf_df.isnull().sum())   # Find sum of all null values for each column\n",
    "# print(sum_NaNs_cf.size)\n",
    "if sum_NaNs_cf.size == array_cf:\n",
    "    cf_df = cf_df.astype(float)\n",
    "    cf_df.columns = cf_headers\n",
    "    cf_df.columns = cf_df.columns.str.replace(',', '_').str.replace('.', '_').str.replace(' ', '') #######\n",
    "cf_df\n",
    "if sum_NaNs_cf.size != array_cf: # and sum_NaNs_cf.size > array_cf:       # If the number of elements do not match, subtract the difference.\n",
    "    how_many_nums_to_delete_cf = sum_NaNs_cf.size - (sum_NaNs_cf.size - array_cf)\n",
    "# print(how_many_nums_to_delete_cf)\n",
    "    p_l_cf = list(sum_NaNs_cf)                 # Convert sum of all null values into a list and sort lowest value to\n",
    "    p_l_cf.sort(reverse=False)                 # to highest value.\n",
    "    # print(p_l_cf[0:how_many_nums_to_delete_cf])  # Then, slice it to the number equal to array_income.\n",
    "\n",
    "    max_new_list_cf = max(p_l_cf[0:how_many_nums_to_delete_cf]) # Find max of sliced list\n",
    "    cf_df_ = cf_df.loc[:, (cf_df.isnull().sum(axis=0) <= max_new_list_cf)] #Delete columns with a certain amount of null values.\n",
    "\n",
    "    cf_df_ =cf_df_.rename(index={'': 'Empty'})\n",
    "    bool_value = cf_df_.index == 'Empty'\n",
    "    index_number = np.where(bool_value)[0]\n",
    "    int_value = int(index_number[0:1])\n",
    "\n",
    "    cf_df_[0:int_value]\n",
    "    cf_df = cf_df_[0:int_value].astype(float)\n",
    "    cf_df.columns = cf_headers\n",
    "    cf_df.columns = cf_df.columns.str.replace(',', '_').str.replace('.', '_').str.replace(' ', '') #######\n",
    "cf_df\n",
    "\n",
    "\n",
    "\n",
    "# ORGANIZING AND CLEANING INCOME STATEMENT - AUTOMATED \n",
    "income_headers = statements_data[2]['headers'][1]\n",
    "# print('Before:',income_headers)\n",
    "drop_1_headers_i = []\n",
    "string_i = ['[1]','[2]','[3]','[4]','[1],[2]']\n",
    "for i in range(0, len(income_headers)) : \n",
    "    if income_headers[i] in string_i : \n",
    "        drop_1_headers_i.append(i) \n",
    "new_headers_i = [j for i, j in enumerate(income_headers) if i not in drop_1_headers_i]\n",
    "# print('After:',new_headers_i)\n",
    "income_headers = [n.replace('\\n','| ') for n in new_headers_i]\n",
    "\n",
    "income_main_header = statements_data[2]['headers'][0]\n",
    "\n",
    "income_data = statements_data[2]['data']\n",
    "example_i = income_data[0:]\n",
    "income_data_ = examples_i = [[x.replace('[1]','').replace('[2]', '').replace('[3]', '').replace('[4]', '') for x in i] for i in example_i]\n",
    "income_data_ = examples_i\n",
    "income_df = pd.DataFrame(income_data_)\n",
    "\n",
    "income_df.index\n",
    "\n",
    "income_df.index = income_df[0] # Make index like column zero \n",
    "income_df.index.name = income_main_header[0] # Pulls name of statement, currency, and number notation.\n",
    "income_df.index.name = income_main_header[0].split('-')[1].replace(' ', '').replace('(', '').replace(')', '').replace(',', '').replace('$', '')\n",
    "income_df = income_df.drop(0, axis = 1)\n",
    "\n",
    "income_df = income_df.replace('[/$,R,,,,,CAD,,,,SFr,)]', '', regex = True)\\\n",
    "                     .replace('[(]','-', regex = True)\\\n",
    "                     .replace('', 'NaN', regex = True)\\\n",
    "                     .replace('[/None)]', np.nan, regex = True)\n",
    "\n",
    "array_income = np.array(income_headers).size   # Count the number of elements for list\n",
    "# print(array_income)\n",
    "sum_NaNs_income = (income_df.isnull().sum())   # Find sum of all null values for each column\n",
    "# print(sum_NaNs_income)\n",
    "# print(sum_NaNs_income.size)\n",
    "if sum_NaNs_income.size == array_income:\n",
    "    income_df = income_df.astype(float)\n",
    "    income_df.columns = income_headers\n",
    "    income_df.columns = cf_df.columns.str.replace(',', '_').str.replace('.', '_').str.replace(' ', '') #######\n",
    "income_df\n",
    "if sum_NaNs_income.size != array_income: #and sum_NaNs_income.size > array_income:       # If the number of elements do not match, subtract the difference.     \n",
    "    how_many_nums_to_delete_income = sum_NaNs_income.size - (sum_NaNs_income.size - array_income)\n",
    "# print(type(how_many_nums_to_delete_income))\n",
    "    p_l_income = list(sum_NaNs_income)             # Convert sum of all null values into a list and sort lowest value to\n",
    "    p_l_income.sort(reverse=False)                 # to highest value.\n",
    "    p_l_income[0:how_many_nums_to_delete_income]   # Then, slice it to the number equal to array_income.\n",
    "\n",
    "    max_new_list_income = max(p_l_income[0:how_many_nums_to_delete_income]) # Find max of sliced list\n",
    "    income_df_ = income_df.loc[:, (income_df.isnull().sum(axis=0) <= max_new_list_income)] #Delete columns with a certain amount of null values.\n",
    "\n",
    "    income_df_ =income_df_.rename(index={'': 'Empty'}) #File blank index ('') with the word ('Empty')\n",
    "    bool_values = income_df_.index == 'Empty'    # Use boolean: When index equals ('Empty'): print 'True'\n",
    "    index_numbers = np.where(bool_values)[0]    \n",
    "    int_values = int(index_numbers[0:1])              # Find index value in an integer term.\n",
    "\n",
    "    income_df_[0:int_values]            # Keep all rows up to, but not including the index value equaled to ('Empty').\n",
    "    income_df = income_df_[0:int_values].astype(float) # Convert to a float\n",
    "    income_df.columns = income_headers               # Substitute the headers list with the dates.\n",
    "    income_df.columns = cf_df.columns.str.replace(',', '_').str.replace('.', '_').str.replace(' ', '') #######\n",
    "income_df\n",
    "\n",
    "\n",
    "\n",
    "# ALL THREE FINANCIAL STATEMENTS WILL BE STORED IN MYSQL. PYTHON IS CONNECTED TO MYSQL BELOW \n",
    "# SCHEMAS, TABLES, COLUMNS, TYPES, NULLABLES, AND ANY OTHER INFORMATION ADDED AND AUTOMATED WITH THE CODE BELOW.\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"YOUR_OWN_PASSWORD\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "mycursor.execute(\"CREATE DATABASE {}\".format(ticker))\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"YOUR_OWN_PASSWORD_HERE\",\n",
    "  database= str(ticker)\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "# cik_id = cik_num \n",
    "index_name_bs = balance_sheet_df.index.name\n",
    "column_zero_bs = balance_sheet_df.columns[0]\n",
    "column_one_bs = balance_sheet_df.columns[1]\n",
    "year_posted = int(column_zero_bs[-2:])\n",
    "table_bs = ticker + '_BS_' + str(year_posted) \n",
    "\n",
    "mycursor.execute('CREATE TABLE {} (ticker INT NOT NULL AUTO_INCREMENT PRIMARY KEY, {} VARCHAR(600), {} INT, {} INT)'.format(table_bs, index_name_bs, column_zero_bs, column_one_bs))\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:PASSWORD@localhost:3306/{}'.format(ticker))\n",
    "balance_sheet_df.to_sql(name = table_bs ,con = engine, if_exists = 'append')\n",
    "\n",
    "table_cf = ticker + '_CF_' + str(year_posted)\n",
    "index_name_cf = cf_df.index.name\n",
    "column_zero_cf = cf_df.columns[0]\n",
    "column_one_cf = cf_df.columns[1]\n",
    "column_two_cf = cf_df.columns[2]\n",
    "\n",
    "mycursor.execute('CREATE TABLE {} (ticker INT NOT NULL AUTO_INCREMENT PRIMARY KEY, {} VARCHAR(600), {} INT, {} INT, {} INT)'.format(table_cf, index_name_cf, column_zero_cf, column_one_cf, column_two_cf))\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:PASSWORD@localhost:3306/{}'.format(ticker))\n",
    "cf_df.to_sql(name = table_cf ,con = engine, if_exists = 'append')\n",
    "\n",
    "table_ic = ticker + '_IC_' + str(year_posted)\n",
    "index_name_ic = income_df.index.name\n",
    "column_zero_ic = income_df.columns[0]\n",
    "column_one_ic = income_df.columns[1]\n",
    "column_two_ic = income_df.columns[2]\n",
    "\n",
    "mycursor.execute('CREATE TABLE {} (ticker INT NOT NULL AUTO_INCREMENT PRIMARY KEY, {} VARCHAR(600), {} INT, {} INT, {} INT)'.format(table_ic, index_name_ic, column_zero_ic, column_one_ic, column_two_ic))\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:PASSWORD@localhost:3306/{}'.format(ticker))\n",
    "income_df.to_sql(name = table_ic ,con = engine, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
